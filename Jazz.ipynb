{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'qa'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-cce36cea8e34>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmusic21\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mqa\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpreprocess\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmusic_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'qa'"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import IPython\n",
    "import sys\n",
    "from music21 import *\n",
    "import numpy as np\n",
    "from qa import *\n",
    "from preprocess import * \n",
    "from music_utils import *\n",
    "from data_utils import *\n",
    "from keras.models import load_model, Model\n",
    "from keras.layers import Dense, Activation, Dropout, Input, LSTM, Reshape, Lambda, RepeatVector\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grammar\n",
    "'''\n",
    "Author:     Ji-Sung Kim, Evan Chow\n",
    "Project:    jazzml / (used in) deepjazz\n",
    "Purpose:    Extract, manipulate, process musical grammar\n",
    "\n",
    "Directly taken then cleaned up from Evan Chow's jazzml, \n",
    "https://github.com/evancchow/jazzml,with permission.\n",
    "'''\n",
    "\n",
    "from collections import OrderedDict, defaultdict\n",
    "from itertools import groupby\n",
    "from music21 import *\n",
    "import copy, random, pdb\n",
    "\n",
    "#from preprocess import *\n",
    "\n",
    "''' Helper function to determine if a note is a scale tone. '''\n",
    "def __is_scale_tone(chord, note):\n",
    "    # Method: generate all scales that have the chord notes th check if note is\n",
    "    # in names\n",
    "\n",
    "    # Derive major or minor scales (minor if 'other') based on the quality\n",
    "    # of the chord.\n",
    "    scaleType = scale.DorianScale() # i.e. minor pentatonic\n",
    "    if chord.quality == 'major':\n",
    "        scaleType = scale.MajorScale()\n",
    "    # Can change later to deriveAll() for flexibility. If so then use list\n",
    "    # comprehension of form [x for a in b for x in a].\n",
    "    scales = scaleType.derive(chord) # use deriveAll() later for flexibility\n",
    "    allPitches = list(set([pitch for pitch in scales.getPitches()]))\n",
    "    allNoteNames = [i.name for i in allPitches] # octaves don't matter\n",
    "\n",
    "    # Get note name. Return true if in the list of note names.\n",
    "    noteName = note.name\n",
    "    return (noteName in allNoteNames)\n",
    "\n",
    "''' Helper function to determine if a note is an approach tone. '''\n",
    "def __is_approach_tone(chord, note):\n",
    "    # Method: see if note is +/- 1 a chord tone.\n",
    "\n",
    "    for chordPitch in chord.pitches:\n",
    "        stepUp = chordPitch.transpose(1)\n",
    "        stepDown = chordPitch.transpose(-1)\n",
    "        if (note.name == stepDown.name or \n",
    "            note.name == stepDown.getEnharmonic().name or\n",
    "            note.name == stepUp.name or\n",
    "            note.name == stepUp.getEnharmonic().name):\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "''' Helper function to determine if a note is a chord tone. '''\n",
    "def __is_chord_tone(lastChord, note):\n",
    "    return (note.name in (p.name for p in lastChord.pitches))\n",
    "\n",
    "''' Helper function to generate a chord tone. '''\n",
    "def __generate_chord_tone(lastChord):\n",
    "    lastChordNoteNames = [p.nameWithOctave for p in lastChord.pitches]\n",
    "    return note.Note(random.choice(lastChordNoteNames))\n",
    "\n",
    "''' Helper function to generate a scale tone. '''\n",
    "def __generate_scale_tone(lastChord):\n",
    "    # Derive major or minor scales (minor if 'other') based on the quality\n",
    "    # of the lastChord.\n",
    "    scaleType = scale.WeightedHexatonicBlues() # minor pentatonic\n",
    "    if lastChord.quality == 'major':\n",
    "        scaleType = scale.MajorScale()\n",
    "    # Can change later to deriveAll() for flexibility. If so then use list\n",
    "    # comprehension of form [x for a in b for x in a].\n",
    "    scales = scaleType.derive(lastChord) # use deriveAll() later for flexibility\n",
    "    allPitches = list(set([pitch for pitch in scales.getPitches()]))\n",
    "    allNoteNames = [i.name for i in allPitches] # octaves don't matter\n",
    "\n",
    "    # Return a note (no octave here) in a scale that matches the lastChord.\n",
    "    sNoteName = random.choice(allNoteNames)\n",
    "    lastChordSort = lastChord.sortAscending()\n",
    "    sNoteOctave = random.choice([i.octave for i in lastChordSort.pitches])\n",
    "    sNote = note.Note((\"%s%s\" % (sNoteName, sNoteOctave)))\n",
    "    return sNote\n",
    "\n",
    "''' Helper function to generate an approach tone. '''\n",
    "def __generate_approach_tone(lastChord):\n",
    "    sNote = __generate_scale_tone(lastChord)\n",
    "    aNote = sNote.transpose(random.choice([1, -1]))\n",
    "    return aNote\n",
    "\n",
    "''' Helper function to generate a random tone. '''\n",
    "def __generate_arbitrary_tone(lastChord):\n",
    "    return __generate_scale_tone(lastChord) # fix later, make random note.\n",
    "\n",
    "\n",
    "''' Given the notes in a measure ('measure') and the chords in that measure\n",
    "    ('chords'), generate a list of abstract grammatical symbols to represent \n",
    "    that measure as described in GTK's \"Learning Jazz Grammars\" (2009). \n",
    "\n",
    "    Inputs: \n",
    "    1) \"measure\" : a stream.Voice object where each element is a\n",
    "        note.Note or note.Rest object.\n",
    "\n",
    "        >>> m1\n",
    "        <music21.stream.Voice 328482572>\n",
    "        >>> m1[0]\n",
    "        <music21.note.Rest rest>\n",
    "        >>> m1[1]\n",
    "        <music21.note.Note C>\n",
    "\n",
    "        Can have instruments and other elements, removes them here.\n",
    "\n",
    "    2) \"chords\" : a stream.Voice object where each element is a chord.Chord.\n",
    "\n",
    "        >>> c1\n",
    "        <music21.stream.Voice 328497548>\n",
    "        >>> c1[0]\n",
    "        <music21.chord.Chord E-4 G4 C4 B-3 G#2>\n",
    "        >>> c1[1]\n",
    "        <music21.chord.Chord B-3 F4 D4 A3>\n",
    "\n",
    "        Can have instruments and other elements, removes them here. \n",
    "\n",
    "    Outputs:\n",
    "    1) \"fullGrammar\" : a string that holds the abstract grammar for measure.\n",
    "        Format: \n",
    "        (Remember, these are DURATIONS not offsets!)\n",
    "        \"R,0.125\" : a rest element of  (1/32) length, or 1/8 quarter note. \n",
    "        \"C,0.125<M-2,m-6>\" : chord note of (1/32) length, generated\n",
    "                             anywhere from minor 6th down to major 2nd down.\n",
    "                             (interval <a,b> is not ordered). '''\n",
    "\n",
    "def parse_melody(fullMeasureNotes, fullMeasureChords):\n",
    "    # Remove extraneous elements.x\n",
    "    measure = copy.deepcopy(fullMeasureNotes)\n",
    "    chords = copy.deepcopy(fullMeasureChords)\n",
    "    measure.removeByNotOfClass([note.Note, note.Rest])\n",
    "    chords.removeByNotOfClass([chord.Chord])\n",
    "\n",
    "    # Information for the start of the measure.\n",
    "    # 1) measureStartTime: the offset for measure's start, e.g. 476.0.\n",
    "    # 2) measureStartOffset: how long from the measure start to the first element.\n",
    "    measureStartTime = measure[0].offset - (measure[0].offset % 4)\n",
    "    measureStartOffset  = measure[0].offset - measureStartTime\n",
    "\n",
    "    # Iterate over the notes and rests in measure, finding the grammar for each\n",
    "    # note in the measure and adding an abstract grammatical string for it. \n",
    "\n",
    "    fullGrammar = \"\"\n",
    "    prevNote = None # Store previous note. Need for interval.\n",
    "    numNonRests = 0 # Number of non-rest elements. Need for updating prevNote.\n",
    "    for ix, nr in enumerate(measure):\n",
    "        # Get the last chord. If no last chord, then (assuming chords is of length\n",
    "        # >0) shift first chord in chords to the beginning of the measure.\n",
    "        try: \n",
    "            lastChord = [n for n in chords if n.offset <= nr.offset][-1]\n",
    "        except IndexError:\n",
    "            chords[0].offset = measureStartTime\n",
    "            lastChord = [n for n in chords if n.offset <= nr.offset][-1]\n",
    "\n",
    "        # FIRST, get type of note, e.g. R for Rest, C for Chord, etc.\n",
    "        # Dealing with solo notes here. If unexpected chord: still call 'C'.\n",
    "        elementType = ' '\n",
    "        # R: First, check if it's a rest. Clearly a rest --> only one possibility.\n",
    "        if isinstance(nr, note.Rest):\n",
    "            elementType = 'R'\n",
    "        # C: Next, check to see if note pitch is in the last chord.\n",
    "        elif nr.name in lastChord.pitchNames or isinstance(nr, chord.Chord):\n",
    "            elementType = 'C'\n",
    "        # L: (Complement tone) Skip this for now.\n",
    "        # S: Check if it's a scale tone.\n",
    "        elif __is_scale_tone(lastChord, nr):\n",
    "            elementType = 'S'\n",
    "        # A: Check if it's an approach tone, i.e. +-1 halfstep chord tone.\n",
    "        elif __is_approach_tone(lastChord, nr):\n",
    "            elementType = 'A'\n",
    "        # X: Otherwise, it's an arbitrary tone. Generate random note.\n",
    "        else:\n",
    "            elementType = 'X'\n",
    "\n",
    "        # SECOND, get the length for each element. e.g. 8th note = R8, but\n",
    "        # to simplify things you'll use the direct num, e.g. R,0.125\n",
    "        if (ix == (len(measure)-1)):\n",
    "            # formula for a in \"a - b\": start of measure (e.g. 476) + 4\n",
    "            diff = measureStartTime + 4.0 - nr.offset\n",
    "        else:\n",
    "            diff = measure[ix + 1].offset - nr.offset\n",
    "\n",
    "        # Combine into the note info.\n",
    "        noteInfo = \"%s,%.3f\" % (elementType, nr.quarterLength) # back to diff\n",
    "\n",
    "        # THIRD, get the deltas (max range up, max range down) based on where\n",
    "        # the previous note was, +- minor 3. Skip rests (don't affect deltas).\n",
    "        intervalInfo = \"\"\n",
    "        if isinstance(nr, note.Note):\n",
    "            numNonRests += 1\n",
    "            if numNonRests == 1:\n",
    "                prevNote = nr\n",
    "            else:\n",
    "                noteDist = interval.Interval(noteStart=prevNote, noteEnd=nr)\n",
    "                noteDistUpper = interval.add([noteDist, \"m3\"])\n",
    "                noteDistLower = interval.subtract([noteDist, \"m3\"])\n",
    "                intervalInfo = \",<%s,%s>\" % (noteDistUpper.directedName, \n",
    "                    noteDistLower.directedName)\n",
    "                # print \"Upper, lower: %s, %s\" % (noteDistUpper,\n",
    "                #     noteDistLower)\n",
    "                # print \"Upper, lower dnames: %s, %s\" % (\n",
    "                #     noteDistUpper.directedName,\n",
    "                #     noteDistLower.directedName)\n",
    "                # print \"The interval: %s\" % (intervalInfo)\n",
    "                prevNote = nr\n",
    "\n",
    "        # Return. Do lazy evaluation for real-time performance.\n",
    "        grammarTerm = noteInfo + intervalInfo \n",
    "        fullGrammar += (grammarTerm + \" \")\n",
    "\n",
    "    return fullGrammar.rstrip()\n",
    "\n",
    "''' Given a grammar string and chords for a measure, returns measure notes. '''\n",
    "def unparse_grammar(m1_grammar, m1_chords):\n",
    "    m1_elements = stream.Voice()\n",
    "    currOffset = 0.0 # for recalculate last chord.\n",
    "    prevElement = None\n",
    "    for ix, grammarElement in enumerate(m1_grammar.split(' ')):\n",
    "        terms = grammarElement.split(',')\n",
    "        currOffset += float(terms[1]) # works just fine\n",
    "\n",
    "        # Case 1: it's a rest. Just append\n",
    "        if terms[0] == 'R':\n",
    "            rNote = note.Rest(quarterLength = float(terms[1]))\n",
    "            m1_elements.insert(currOffset, rNote)\n",
    "            continue\n",
    "\n",
    "        # Get the last chord first so you can find chord note, scale note, etc.\n",
    "        try: \n",
    "            lastChord = [n for n in m1_chords if n.offset <= currOffset][-1]\n",
    "        except IndexError:\n",
    "            m1_chords[0].offset = 0.0\n",
    "            lastChord = [n for n in m1_chords if n.offset <= currOffset][-1]\n",
    "\n",
    "        # Case: no < > (should just be the first note) so generate from range\n",
    "        # of lowest chord note to highest chord note (if not a chord note, else\n",
    "        # just generate one of the actual chord notes). \n",
    "\n",
    "        # Case #1: if no < > to indicate next note range. Usually this lack of < >\n",
    "        # is for the first note (no precedent), or for rests.\n",
    "        if (len(terms) == 2): # Case 1: if no < >.\n",
    "            insertNote = note.Note() # default is C\n",
    "\n",
    "            # Case C: chord note.\n",
    "            if terms[0] == 'C':\n",
    "                insertNote = __generate_chord_tone(lastChord)\n",
    "\n",
    "            # Case S: scale note.\n",
    "            elif terms[0] == 'S':\n",
    "                insertNote = __generate_scale_tone(lastChord)\n",
    "\n",
    "            # Case A: approach note.\n",
    "            # Handle both A and X notes here for now.\n",
    "            else:\n",
    "                insertNote = __generate_approach_tone(lastChord)\n",
    "\n",
    "            # Update the stream of generated notes\n",
    "            insertNote.quarterLength = float(terms[1])\n",
    "            if insertNote.octave < 4:\n",
    "                insertNote.octave = 4\n",
    "            m1_elements.insert(currOffset, insertNote)\n",
    "            prevElement = insertNote\n",
    "\n",
    "        # Case #2: if < > for the increment. Usually for notes after the first one.\n",
    "        else:\n",
    "            # Get lower, upper intervals and notes.\n",
    "            interval1 = interval.Interval(terms[2].replace(\"<\",''))\n",
    "            interval2 = interval.Interval(terms[3].replace(\">\",''))\n",
    "            if interval1.cents > interval2.cents:\n",
    "                upperInterval, lowerInterval = interval1, interval2\n",
    "            else:\n",
    "                upperInterval, lowerInterval = interval2, interval1\n",
    "            lowPitch = interval.transposePitch(prevElement.pitch, lowerInterval)\n",
    "            highPitch = interval.transposePitch(prevElement.pitch, upperInterval)\n",
    "            numNotes = int(highPitch.ps - lowPitch.ps + 1) # for range(s, e)\n",
    "\n",
    "            # Case C: chord note, must be within increment (terms[2]).\n",
    "            # First, transpose note with lowerInterval to get note that is\n",
    "            # the lower bound. Then iterate over, and find valid notes. Then\n",
    "            # choose randomly from those.\n",
    "            \n",
    "            if terms[0] == 'C':\n",
    "                relevantChordTones = []\n",
    "                for i in range(0, numNotes):\n",
    "                    currNote = note.Note(lowPitch.transpose(i).simplifyEnharmonic())\n",
    "                    if __is_chord_tone(lastChord, currNote):\n",
    "                        relevantChordTones.append(currNote)\n",
    "                if len(relevantChordTones) > 1:\n",
    "                    insertNote = random.choice([i for i in relevantChordTones\n",
    "                        if i.nameWithOctave != prevElement.nameWithOctave])\n",
    "                elif len(relevantChordTones) == 1:\n",
    "                    insertNote = relevantChordTones[0]\n",
    "                else: # if no choices, set to prev element +-1 whole step\n",
    "                    insertNote = prevElement.transpose(random.choice([-2,2]))\n",
    "                if insertNote.octave < 3:\n",
    "                    insertNote.octave = 3\n",
    "                insertNote.quarterLength = float(terms[1])\n",
    "                m1_elements.insert(currOffset, insertNote)\n",
    "\n",
    "            # Case S: scale note, must be within increment.\n",
    "            elif terms[0] == 'S':\n",
    "                relevantScaleTones = []\n",
    "                for i in range(0, numNotes):\n",
    "                    currNote = note.Note(lowPitch.transpose(i).simplifyEnharmonic())\n",
    "                    if __is_scale_tone(lastChord, currNote):\n",
    "                        relevantScaleTones.append(currNote)\n",
    "                if len(relevantScaleTones) > 1:\n",
    "                    insertNote = random.choice([i for i in relevantScaleTones\n",
    "                        if i.nameWithOctave != prevElement.nameWithOctave])\n",
    "                elif len(relevantScaleTones) == 1:\n",
    "                    insertNote = relevantScaleTones[0]\n",
    "                else: # if no choices, set to prev element +-1 whole step\n",
    "                    insertNote = prevElement.transpose(random.choice([-2,2]))\n",
    "                if insertNote.octave < 3:\n",
    "                    insertNote.octave = 3\n",
    "                insertNote.quarterLength = float(terms[1])\n",
    "                m1_elements.insert(currOffset, insertNote)\n",
    "\n",
    "            # Case A: approach tone, must be within increment.\n",
    "            # For now: handle both A and X cases.\n",
    "            else:\n",
    "                relevantApproachTones = []\n",
    "                for i in range(0, numNotes):\n",
    "                    currNote = note.Note(lowPitch.transpose(i).simplifyEnharmonic())\n",
    "                    if __is_approach_tone(lastChord, currNote):\n",
    "                        relevantApproachTones.append(currNote)\n",
    "                if len(relevantApproachTones) > 1:\n",
    "                    insertNote = random.choice([i for i in relevantApproachTones\n",
    "                        if i.nameWithOctave != prevElement.nameWithOctave])\n",
    "                elif len(relevantApproachTones) == 1:\n",
    "                    insertNote = relevantApproachTones[0]\n",
    "                else: # if no choices, set to prev element +-1 whole step\n",
    "                    insertNote = prevElement.transpose(random.choice([-2,2]))\n",
    "                if insertNote.octave < 3:\n",
    "                    insertNote.octave = 3\n",
    "                insertNote.quarterLength = float(terms[1])\n",
    "                m1_elements.insert(currOffset, insertNote)\n",
    "\n",
    "            # update the previous element.\n",
    "            prevElement = insertNote\n",
    "\n",
    "    return m1_elements    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-d9e3f2f6e03f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRepeatVector\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras.layers import RepeatVector\n",
    "import sys\n",
    "from music21 import *\n",
    "import numpy as np\n",
    "from grammar import *\n",
    "from preprocess import *\n",
    "from qa import *\n",
    "\n",
    "\n",
    "def data_processing(corpus, values_indices, m = 60, Tx = 30):\n",
    "    # cut the corpus into semi-redundant sequences of Tx values\n",
    "    Tx = Tx \n",
    "    N_values = len(set(corpus))\n",
    "    np.random.seed(0)\n",
    "    X = np.zeros((m, Tx, N_values), dtype=np.bool)\n",
    "    Y = np.zeros((m, Tx, N_values), dtype=np.bool)\n",
    "    for i in range(m):\n",
    "#         for t in range(1, Tx):\n",
    "        random_idx = np.random.choice(len(corpus) - Tx)\n",
    "        corp_data = corpus[random_idx:(random_idx + Tx)]\n",
    "        for j in range(Tx):\n",
    "            idx = values_indices[corp_data[j]]\n",
    "            if j != 0:\n",
    "                X[i, j, idx] = 1\n",
    "                Y[i, j-1, idx] = 1\n",
    "    \n",
    "    Y = np.swapaxes(Y,0,1)\n",
    "    Y = Y.tolist()\n",
    "    return np.asarray(X), np.asarray(Y), N_values \n",
    "\n",
    "def next_value_processing(model, next_value, x, predict_and_sample, indices_values, abstract_grammars, duration, max_tries = 1000, temperature = 0.5):\n",
    "    \"\"\"\n",
    "    Helper function to fix the first value.\n",
    "    \n",
    "    Arguments:\n",
    "    next_value -- predicted and sampled value, index between 0 and 77\n",
    "    x -- numpy-array, one-hot encoding of next_value\n",
    "    predict_and_sample -- predict function\n",
    "    indices_values -- a python dictionary mapping indices (0-77) into their corresponding unique value (ex: A,0.250,< m2,P-4 >)\n",
    "    abstract_grammars -- list of grammars, on element can be: 'S,0.250,<m2,P-4> C,0.250,<P4,m-2> A,0.250,<P4,m-2>'\n",
    "    duration -- scalar, index of the loop in the parent function\n",
    "    max_tries -- Maximum numbers of time trying to fix the value\n",
    "    \n",
    "    Returns:\n",
    "    next_value -- process predicted value\n",
    "    \"\"\"\n",
    "\n",
    "    # fix first note: must not have < > and not be a rest\n",
    "    if (duration < 0.00001):\n",
    "        tries = 0\n",
    "        while (next_value.split(',')[0] == 'R' or \n",
    "            len(next_value.split(',')) != 2):\n",
    "            # give up after 1000 tries; random from input's first notes\n",
    "            if tries >= max_tries:\n",
    "                #print('Gave up on first note generation after', max_tries, 'tries')\n",
    "                # np.random is exclusive to high\n",
    "                rand = np.raandom.randint(0, len(abstract_grammars))\n",
    "                next_value = abstract_grammars[rand].split(' ')[0]\n",
    "            else:\n",
    "                next_value = predict_and_sample(model, x, indices_values, temperature)\n",
    "\n",
    "            tries += 1\n",
    "            \n",
    "    return next_value\n",
    "\n",
    "\n",
    "def sequence_to_matrix(sequence, values_indices):\n",
    "    \"\"\"\n",
    "    Convert a sequence (slice of the corpus) into a matrix (numpy) of one-hot vectors corresponding \n",
    "    to indices in values_indices\n",
    "    \n",
    "    Arguments:\n",
    "    sequence -- python list\n",
    "    \n",
    "    Returns:\n",
    "    x -- numpy-array of one-hot vectors \n",
    "    \"\"\"\n",
    "    sequence_len = len(sequence)\n",
    "    x = np.zeros((1, sequence_len, len(values_indices)))\n",
    "    for t, value in enumerate(sequence):\n",
    "        if (not value in values_indices): print(value)\n",
    "        x[0, t, values_indices[value]] = 1.\n",
    "    return x\n",
    "\n",
    "def one_hot(x):\n",
    "    x = K.argmax(x)\n",
    "    x = tf.one_hot(x, 78) \n",
    "    x = RepeatVector(1)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "rate must be specified when data is a numpy array or list of audio samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-79d15e8f4cf9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mIPython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAudio\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./data/30s_seq.mp3'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\lib\\display.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, filename, url, embed, rate, autoplay, normalize, element_id)\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mrate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"rate must be specified when data is a numpy array or list of audio samples.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAudio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_wav\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: rate must be specified when data is a numpy array or list of audio samples."
     ]
    }
   ],
   "source": [
    "IPython.display.Audio('./data/30s_seq.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, n_values, indices_values = load_music_utils()\n",
    "print('number of training examples:', X.shape[0])\n",
    "print('Tx (length of sequence):', X.shape[1])\n",
    "print('total # of unique values:', n_values)\n",
    "print('shape of X:', X.shape)\n",
    "print('Shape of Y:', Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of dimensions for the hidden state of each LSTM cell.\n",
    "n_a = 64 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_values = 78 # number of music values\n",
    "reshapor = Reshape((1, n_values))                        # Used in Step 2.B of djmodel(), below\n",
    "LSTM_cell = LSTM(n_a, return_state = True)         # Used in Step 2.C\n",
    "densor = Dense(n_values, activation='softmax')     # Used in Step 2.D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: djmodel\n",
    "\n",
    "def djmodel(Tx, n_a, n_values):\n",
    "    \"\"\"\n",
    "    Implement the model\n",
    "    \n",
    "    Arguments:\n",
    "    Tx -- length of the sequence in a corpus\n",
    "    n_a -- the number of activations used in our model\n",
    "    n_values -- number of unique values in the music data \n",
    "    \n",
    "    Returns:\n",
    "    model -- a keras instance model with n_a activations\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the input layer and specify the shape\n",
    "    X = Input(shape=(Tx, n_values))\n",
    "    \n",
    "    # Define the initial hidden state a0 and initial cell state c0\n",
    "    # using `Input`\n",
    "    a0 = Input(shape=(n_a,), name='a0')\n",
    "    c0 = Input(shape=(n_a,), name='c0')\n",
    "    a = a0\n",
    "    c = c0\n",
    "    \n",
    "    ### START CODE HERE ### \n",
    "    # Step 1: Create empty list to append the outputs while you iterate (≈1 line)\n",
    "    outputs = []\n",
    "    \n",
    "    # Step 2: Loop\n",
    "    for t in range(Tx):\n",
    "        \n",
    "        # Step 2.A: select the \"t\"th time step vector from X. \n",
    "        x = Lambda(lambda z: z[t])(X)\n",
    "        # Step 2.B: Use reshapor to reshape x to be (1, n_values) (≈1 line)\n",
    "        x = reshapor(x)\n",
    "        # Step 2.C: Perform one step of the LSTM_cell\n",
    "        a, _, c = LSTM_cell(inputs=x, initial_state=[a, c])\n",
    "        # Step 2.D: Apply densor to the hidden state output of LSTM_Cell\n",
    "        out = densor(a)\n",
    "        # Step 2.E: add the output to \"outputs\"\n",
    "        outputs.append(out)\n",
    "        \n",
    "    # Step 3: Create model instance\n",
    "    model = Model(inputs=[X, a0, c0], outputs = outputs)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = djmodel(Tx = 30 , n_a = 64, n_values = 78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check your model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Adam' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-6786c091500c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mopt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta_1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta_2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.999\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Adam' is not defined"
     ]
    }
   ],
   "source": [
    "opt = Adam(lr=0.01, beta_1=0.9, beta_2=0.999, decay=0.01)\n",
    "\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 60\n",
    "a0 = np.zeros((m, n_a))\n",
    "c0 = np.zeros((m, n_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit([X, a0, c0], list(Y), epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: music_inference_model\n",
    "\n",
    "def music_inference_model(LSTM_cell, densor, n_values = 78, n_a = 64, Ty = 100):\n",
    "    \"\"\"\n",
    "    Uses the trained \"LSTM_cell\" and \"densor\" from model() to generate a sequence of values.\n",
    "    \n",
    "    Arguments:\n",
    "    LSTM_cell -- the trained \"LSTM_cell\" from model(), Keras layer object\n",
    "    densor -- the trained \"densor\" from model(), Keras layer object\n",
    "    n_values -- integer, number of unique values\n",
    "    n_a -- number of units in the LSTM_cell\n",
    "    Ty -- integer, number of time steps to generate\n",
    "    \n",
    "    Returns:\n",
    "    inference_model -- Keras model instance\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the input of your model with a shape \n",
    "    x0 = Input(shape=(1, n_values))\n",
    "    \n",
    "    # Define s0, initial hidden state for the decoder LSTM\n",
    "    a0 = Input(shape=(n_a,), name='a0')\n",
    "    c0 = Input(shape=(n_a,), name='c0')\n",
    "    a = a0\n",
    "    c = c0\n",
    "    x = x0\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "    # Step 1: Create an empty list of \"outputs\" to later store your predicted values (≈1 line)\n",
    "    outputs = []\n",
    "    \n",
    "    # Step 2: Loop over Ty and generate a value at every time step\n",
    "    for t in range(Ty):\n",
    "        \n",
    "        # Step 2.A: Perform one step of LSTM_cell (≈1 line)\n",
    "        a, _, c = LSTM_cell(inputs=x, initial_state=[a, c])\n",
    "        \n",
    "        # Step 2.B: Apply Dense layer to the hidden state output of the LSTM_cell (≈1 line)\n",
    "        out = densor(a)\n",
    "\n",
    "        # Step 2.C: Append the prediction \"out\" to \"outputs\". out.shape = (None, 78) (≈1 line)\n",
    "        outputs.append(out)\n",
    "        \n",
    "        # Step 2.D: \n",
    "        # Select the next value according to \"out\",\n",
    "        # Set \"x\" to be the one-hot representation of the selected value\n",
    "        # See instructions above.\n",
    "        x = Lambda(one_hot)(out)\n",
    "        \n",
    "    # Step 3: Create model instance with the correct \"inputs\" and \"outputs\" (≈1 line)\n",
    "    inference_model = Model(inputs=[x0, a0, c0], outputs=outputs)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return inference_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_model = music_inference_model(LSTM_cell, densor, n_values = 78, n_a = 64, Ty = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the inference model\n",
    "inference_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_initializer = np.zeros((1, 1, 78))\n",
    "a_initializer = np.zeros((1, n_a))\n",
    "c_initializer = np.zeros((1, n_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: predict_and_sample\n",
    "\n",
    "def predict_and_sample(inference_model, x_initializer = x_initializer, a_initializer = a_initializer, \n",
    "                       c_initializer = c_initializer):\n",
    "    \"\"\"\n",
    "    Predicts the next value of values using the inference model.\n",
    "    \n",
    "    Arguments:\n",
    "    inference_model -- Keras model instance for inference time\n",
    "    x_initializer -- numpy array of shape (1, 1, 78), one-hot vector initializing the values generation\n",
    "    a_initializer -- numpy array of shape (1, n_a), initializing the hidden state of the LSTM_cell\n",
    "    c_initializer -- numpy array of shape (1, n_a), initializing the cell state of the LSTM_cel\n",
    "    \n",
    "    Returns:\n",
    "    results -- numpy-array of shape (Ty, 78), matrix of one-hot vectors representing the values generated\n",
    "    indices -- numpy-array of shape (Ty, 1), matrix of indices representing the values generated\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # Step 1: Use your inference model to predict an output sequence given x_initializer, a_initializer and c_initializer.\n",
    "    pred = inference_model.predict([x_initializer, a_initializer, c_initializer])\n",
    "    # Step 2: Convert \"pred\" into an np.array() of indices with the maximum probabilities\n",
    "    indices = np.argmax(pred, axis = 2)\n",
    "    # Step 3: Convert indices to one-hot vectors, the shape of the results should be (Ty, n_values)\n",
    "    results = to_categorical(indices, num_classes = x_initializer.shape[2])\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return results, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results, indices = predict_and_sample(inference_model, x_initializer, a_initializer, c_initializer)\n",
    "print(\"np.argmax(results[12]) =\", np.argmax(results[12]))\n",
    "print(\"np.argmax(results[17]) =\", np.argmax(results[17]))\n",
    "print(\"list(indices[12:18]) =\", list(indices[12:18]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_stream = generate_music(inference_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IPython.display.Audio('./output/30s_trained_model.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
